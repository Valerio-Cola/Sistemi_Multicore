\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{verbatim}
\usepackage{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}

% Definizione colori
\definecolor{codegray}{rgb}{0.95,0.95,0.95}
\definecolor{codeframe}{rgb}{0.8,0.8,0.8}

% Configurazione listings
\lstset{
    backgroundcolor=\color{codegray},
    frame=single,
    rulecolor=\color{codeframe},
    basicstyle=\ttfamily\small,
    breaklines=true,
    numbers=none,
    xleftmargin=3mm,
    framexleftmargin=3mm,
    framexrightmargin=3mm,
    framextopmargin=2mm,
    framexbottommargin=2mm,
    language=C++
}

% Definizione nuovo ambiente per il codice
\newcommand{\code}[1]{\begin{lstlisting}#1\end{lstlisting}}

% Definisci i colori per la sintassi
\definecolor{commentcolor}{rgb}{0.13,0.55,0.13}
\definecolor{keywordcolor}{rgb}{0.13,0.13,1}
\definecolor{stringcolor}{rgb}{0.9,0.1,0.1}

% Configura l'ambiente listings con i colori
\lstset{
    language=C,
    basicstyle=\ttfamily\footnotesize,
    breaklines=true,
    frame=single,
    commentstyle=\color{commentcolor},
    keywordstyle=\color{keywordcolor},
    stringstyle=\color{stringcolor},
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    tabsize=2,
    showstringspaces=false,
    captionpos=b
}

% Configura i margini
\geometry{
  a4paper,
  left=25mm,
  right=25mm,
  top=25mm,
  bottom=25mm
}

\begin{document}

\section{MPI}

\subsection{Inizializzazione MPI con comunicatore}
\begin{verbatim}
int r = MPI_Init(NULL, NULL);
int size, rank;
MPI_Comm_size(MPI_COMM_WORLD, &size);
MPI_Comm_rank(MPI_COMM_WORLD, &rank);
\end{verbatim}

\subsection{Chiusura MPI}
\begin{verbatim}
MPI_Finalize();
\end{verbatim}

\subsection{Lancio errore}
\begin{verbatim}
MPI_Abort(MPI_COMM_WORLD, r);
\end{verbatim}

\subsection{Bloccanti}
\begin{verbatim}
int MPI_Send(
    void* msg_buf_p,          // Puntatore ai dati
    int msg_size,             // Numero di elementi nel messaggio
    MPI_Datatype msg_type,    // Tipo di dato nel messaggio
    int dest,                 // Rank processo a cui inviare
    int tag,
    MPI_Comm communicator     // Comunicatore
);

int MPI_Recv(
    void* msg_buf_p,          // Puntatore ai dati
    int buf_size,
    MPI_Datatype buf_type,
    int source,               // Rank processo da cui riceve
    int tag,
    MPI_Comm communicator,
    MPI_Status* status_p      // Utilizziamo MPI_STATUS_IGNORE
);
\end{verbatim}

\subsection{Non bloccanti}
\begin{itemize}
    \item \texttt{Isend}
    \item \texttt{Irecv}
\end{itemize}

\subsection{Tag}
\begin{itemize}
    \item \texttt{MPI\_ANY\_SOURCE} è possibile ricevere da chiunque
    \item \texttt{MPI\_ANY\_TAG} è possibile ricevere msg con qualsiasi tag
\end{itemize}

\subsection{Tipi di dato}
\begin{itemize}
    \item \texttt{MPI\_CHAR}
    \item \texttt{MPI\_SIGNED\_CHAR}
    \item \texttt{MPI\_UNSIGNED\_CHAR}
    \item \texttt{MPI\_BYTE}
    \item \texttt{MPI\_WCHAR}
    \item \texttt{MPI\_SHORT}
    \item \texttt{MPI\_UNSIGNED\_SHORT}
    \item \texttt{MPI\_INT}
    \item \texttt{MPI\_UNSIGNED}
    \item \texttt{MPI\_LONG}
    \item \texttt{MPI\_UNSIGNED\_LONG}
    \item \texttt{MPI\_LONG\_LONG\_INT}
    \item \texttt{MPI\_UNSIGNED\_LONG\_LONG}
    \item \texttt{MPI\_FLOAT}
    \item \texttt{MPI\_DOUBLE}
    \item \texttt{MPI\_LONG\_DOUBLE}
\end{itemize}

\subsection{Comunicazione tra processi}
Ogni processo utilizza due buffer invio e ricezione per scambiarsi dati:
\begin{verbatim}
MPI_Alltoall(sendbuf, 1, MPI_INT, recvbuf, 1, MPI_INT, MPI_COMM_WORLD);
\end{verbatim}

\subsection{Inizializzo richiesta}
\begin{verbatim}
MPI_Request request_send_r, request_send_l;
\end{verbatim}

Da inserire dopo le \texttt{send} e \texttt{recv} per bloccare il processo affinché non vengono completate:
\begin{verbatim}
MPI_Wait(&request_send_l, MPI_STATUS_IGNORE);
MPI_Wait(&request_send_r, MPI_STATUS_IGNORE);
\end{verbatim}

\subsection{Richieste inizializzate mediante lista}
\begin{lstlisting}
MPI_Request lista_richieste[4];
\end{lstlisting}

Attende che tutte le \texttt{recv} e \texttt{send} della lista vengano completate:
\begin{lstlisting}
MPI_Waitall(4, lista_richieste, MPI_STATUS_IGNORE);
\end{lstlisting}

\subsection{Broadcast}
Broadcast dei valori della variabile \texttt{a} a tutti i processi:
\begin{lstlisting}
MPI_Bcast(a, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD);
\end{lstlisting}

\subsection{Reduce}
Ogni processo prende l'indirizzo della variabile calcolata e la somma a \texttt{int\_totale}:
\begin{lstlisting}
MPI_Reduce(&int_locale, &int_totale, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
\end{lstlisting}

\subsubsection{Operazioni di riduzione}
\begin{itemize}
    \item \texttt{MPI\_MAX} Massimo
    \item \texttt{MPI\_MIN} Minimo
    \item \texttt{MPI\_SUM} Somma
    \item \texttt{MPI\_PROD} Prodotto
    \item \texttt{MPI\_LAND} AND logico
    \item \texttt{MPI\_LOR} OR logico
    \item \texttt{MPI\_LXOR} XOR logico
    \item \texttt{MPI\_BAND} Bitwise AND
    \item \texttt{MPI\_BOR} Bitwise OR
    \item \texttt{MPI\_BXOR} Bitwise XOR
\end{itemize}

\subsection{Calcolo tempo esecuzione}
Ritornano dei \texttt{double}:
\begin{lstlisting}
inizio = MPI_Wtime();
/*    code    */
fine = MPI_Wtime();
\end{lstlisting}

\subsection{Scatter}
Root invia il vettore spezzato in parti uguali:
\begin{lstlisting}
MPI_Scatter(a, len_vect / size, MPI_INT, MPI_IN_PLACE, len_vect / size, MPI_INT, 0, MPI_COMM_WORLD);
\end{lstlisting}

Ogni processo dovrà farlo per ottenere il vettore \texttt{a}:
\begin{lstlisting}
MPI_Scatter(NULL, len_vect / size, MPI_INT, a, len_vect / size, MPI_INT, 0, MPI_COMM_WORLD);
\end{lstlisting}

\subsection{Gather}
Ogni processo invia il proprio pezzo di vettore \texttt{c} al vettore finale:
\begin{lstlisting}
MPI_Gather(c, len_vect / size, MPI_INT, finale, len_vect / size, MPI_INT, 0, MPI_COMM_WORLD);
\end{lstlisting}

\subsection{Broadcast del vettore}
Broadcast del vettore \texttt{x} a tutti i processi:
\begin{verbatim}
MPI_Bcast(x, colonne, MPI_INT, 0, MPI_COMM_WORLD);
\end{verbatim}

\subsection{Strutture}
\begin{verbatim}
MPI_Datatype t;
int block_lengths[3] = {1, 1, 1}; // Numero di elementi per tipo
MPI_Aint displacements[3] = {0, 16, 24}; // Offset di memoria
MPI_Datatype types[3] = {MPI_DOUBLE, MPI_DOUBLE, MPI_INT};
\end{verbatim}

Genera struttura:
\begin{verbatim}
MPI_Type_create_struct(3, block_lengths, displacements, types, &t);
\end{verbatim}

Necessario per essere ottimizzato per le comunicazioni:
\begin{verbatim}
MPI_Type_commit(&t);
\end{verbatim}

Libera memoria struttura:
\begin{verbatim}
MPI_Type_free(&t);
\end{verbatim}

\section{PTHREAD}

\subsection{Creazione di un Thread}
\begin{lstlisting}
int pthread_create(
    pthread_t *thread,                  // Puntatore alla struttura che                                     identifica il thread
    const pthread_attr_t *attr,         // NULL o attributi del thread
    void *(*start_routine) (void *),    // Puntatore alla funzione che                                      il thread eseguira'
    void *arg                           // Argomento della funzione
);
\end{lstlisting}
Esempio di utilizzo:
\begin{verbatim}
pthread_create(NULL, NULL, my_function, (void*)10);
\end{verbatim}
Questa chiamata crea un nuovo thread che esegue \texttt{my\_function} con l'argomento \texttt{10}.

\subsection{Attesa della Terminazione di un Thread}
\begin{verbatim}
int pthread_join(pthread_t thread, void **value_ptr);
\end{verbatim}
Questa funzione fa attendere il thread chiamante fino alla terminazione del thread specificato.

\subsection{Identificazione del Thread Corrente}
\begin{verbatim}
pthread_t pthread_self(void);
\end{verbatim}
Restituisce l'ID del thread chiamante.

\subsection{Confronto di ID di Thread}
\begin{verbatim}
int pthread_equal(pthread_t t1, pthread_t t2);
\end{verbatim}
Confronta gli ID di due thread e restituisce un valore diverso da zero se sono uguali.

\subsection{Semafori}

\subsubsection{Inizializzazione del Semaforo}
\begin{verbatim}
int sem_init(sem_t *sem, int pshared, unsigned int value);
\end{verbatim}
Inizializza un semaforo con un valore iniziale.

\subsubsection{Attesa su un Semaforo}
\begin{verbatim}
int sem_wait(sem_t *sem);
\end{verbatim}
Decrementa il semaforo. Se il valore è 0, il thread viene bloccato fino a quando il semaforo non viene incrementato.

\subsubsection{Segnalazione su un Semaforo}
\begin{verbatim}
int sem_post(sem_t *sem);
\end{verbatim}
Incrementa il semaforo e, se ci sono thread in attesa, ne sblocca uno.

\subsubsection{Ottenere il Valore del Semaforo}
\begin{verbatim}
int sem_getvalue(sem_t *sem, int *sval);
\end{verbatim}
Recupera il valore corrente del semaforo.

\subsubsection{Distruzione del Semaforo}
\begin{verbatim}
int sem_destroy(sem_t *sem);
\end{verbatim}
Rimuove il semaforo e libera le risorse.

\subsection{RWLock (Read-Write Lock)}

\subsubsection{Inizializzazione del RWLock}
\begin{lstlisting}
int pthread_rwlock_init(pthread_rwlock_t* rwlock, const pthread_rwlockattr_t* attr);
\end{lstlisting}
Inizializza un read-write lock.

\subsubsection{Bloccare in Modalità Lettura}
\begin{verbatim}
int pthread_rwlock_rdlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Blocca il rwlock per letture condivise.

\subsubsection{Bloccare in Modalità Scrittura}
\begin{verbatim}
int pthread_rwlock_wrlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Blocca il rwlock per scritture esclusive.

\subsubsection{Sbloccare il RWLock}
\begin{verbatim}
int pthread_rwlock_unlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Sblocca il rwlock.

\subsubsection{Distruzione del RWLock}
\begin{verbatim}
int pthread_rwlock_destroy(pthread_rwlock_t* rwlock);
\end{verbatim}
Distrugge il rwlock e libera le risorse.

\subsection{Mutex}

\subsubsection{Inizializzazione del Mutex}
\begin{lstlisting}
int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr);
\end{lstlisting}
Inizializza un mutex.

\subsubsection{Bloccare il Mutex}
\begin{verbatim}
int pthread_mutex_lock(pthread_mutex_t *mutex);
\end{verbatim}
Blocca il mutex. Se il mutex è già bloccato, il thread chiamante viene messo in attesa.

\subsubsection{Sbloccare il Mutex}
\begin{verbatim}
int pthread_mutex_unlock(pthread_mutex_t *mutex);
\end{verbatim}
Sblocca il mutex.

\subsubsection{Distruzione del Mutex}
\begin{verbatim}
int pthread_mutex_destroy(pthread_mutex_t *mutex);
\end{verbatim}
Rimuove il mutex e libera le risorse.

\subsubsection{Esempio di Utilizzo del Mutex}
\begin{verbatim}
pthread_mutex_lock(&mutex);
sum += 4 * my_sum;
pthread_mutex_unlock(&mutex);
\end{verbatim}
Questo esempio dimostra come proteggere una sezione critica utilizzando un mutex.

\section{OpenMPI}

\subsection{Esecuzione della funzione \texttt{Hello()} in parallelo con \texttt{num\_thread} thread}
\begin{verbatim}
#pragma omp parallel num_threads(num_thread)
Hello();
\end{verbatim}

Oppure, puoi impostare il numero di thread in questo modo:

\begin{verbatim}
omp_set_num_threads(int num_threads);
\end{verbatim}

\subsection{Clausole di Condivisione delle Variabili}
Quando aggiungi una pragma, puoi specificare come le variabili sono condivise tra i thread:
\begin{itemize}
    \item \textbf{private(variabile)}: Ogni thread ha la propria copia della variabile, indipendente da quella esterna.
    \item \textbf{shared}: Tutte le variabili sono condivise tra i thread.
    \item \textbf{none}: Nessuna variabile è condivisa; tutte devono avere uno scope esplicito.
    \item \textbf{reduction(operatore:variabile)}: Le variabili sono private, tranne \texttt{variabile} che è utilizzata per la riduzione con l'\texttt{operatore} specificato.
    \item \textbf{firstprivate}: Le variabili sono private e inizializzate con il valore della variabile esterna.
    \item \textbf{lastprivate}: Le variabili sono private e il loro valore viene copiato nella variabile esterna dopo il blocco.
    \item \textbf{threadprivate}: Le variabili sono private e mantengono il loro valore tra diverse regioni parallel.
    \item \textbf{copyin}: Le variabili sono private e inizializzate con il valore della variabile esterna all'inizio del blocco.
    \item \textbf{copyprivate}: Simile a \texttt{copyin}, ma i valori vengono copiati anche al termine del blocco.
\end{itemize}

\subsection{Operazioni di Riduzione}
\begin{verbatim}
reduction(operatore:variabile)
\end{verbatim}

Operatori supportati: \texttt{+}, \texttt{*}, \texttt{-}, \texttt{\&}, \texttt{ |}, \texttt{\^}, \texttt{\&\&}, \texttt{||}. Ogni thread esegue l'operazione e accumula il risultato in una singola variabile.

\subsection{Controllo della Concorrenza}
\begin{itemize}
    \item \textbf{critical}: Simile a un lock, garantisce che solo un thread acceda alla sezione critica alla volta.
    \item \textbf{atomic}: Garantisce l'esecuzione atomica di operazioni specifiche, migliorando le prestazioni rispetto a \texttt{critical} quando applicabile.
\end{itemize}

\subsection{Parallelizzazione dei Cicli}
\begin{itemize}
    \item \textbf{for}: Parallelizza l'esecuzione del ciclo \texttt{for}, anche quelli annidati, a seconda della posizione della pragma.
    \item \textbf{collapse(numero\_for)}: Insieme a \texttt{for}, OpenMPI gestisce la parallelizzazione di più cicli annidati.
\end{itemize}

\subsection{Misurazione del Tempo di Esecuzione}
\begin{verbatim}
double start = omp_get_wtime();
/* codice */
double stop = omp_get_wtime();
\end{verbatim}

Calcola il tempo di esecuzione del codice tra le due chiamate a \texttt{omp\_get\_wtime()}.

\section{CUDA}

\subsection{Chiamata alla funzione \texttt{hello}}
Esecuzione della funzione \texttt{hello} in un singolo blocco con 10 thread. La chiamata è asincrona, quindi è necessario sincronizzare la GPU per attendere il completamento dell'esecuzione.
\begin{verbatim}
hello<<<1, 10>>>();
cudaDeviceSynchronize();
\end{verbatim}

\subsection{Decoratori per funzioni CUDA}
\begin{itemize}
    \item \texttt{\_\_global\_\_}: Indica che la funzione è eseguita sulla GPU e può essere chiamata dalla CPU.
    \item \texttt{\_\_device\_\_}: Indica che la funzione è eseguita sulla GPU ma può essere chiamata solo da altre funzioni eseguite sulla GPU.
    \item \texttt{\_\_host\_\_}: Indica che la funzione è eseguita sulla CPU.
\end{itemize}

\subsection{Numero di GPU disponibili}
Ottiene il numero di GPU disponibili nel sistema.
\begin{verbatim}
int deviceCount = 0;
cudaGetDeviceCount(&deviceCount);
\end{verbatim}

\subsection{Proprietà delle GPU}
Ad ogni GPU è assegnata una struttura per le relative informazioni.
\begin{lstlisting}
struct cudaDeviceProp {
    char name[256]; // Nome del device
    int major; // Major compute capability number
    int minor; // Minor compute capability number
    int maxGridSize[3]; // Dimensioni massime della griglia
    int maxThreadsDim[3]; // Dimensioni massime dei blocchi
    int maxThreadsPerBlock; // Numero massimo di thread per blocco
    int maxThreadsPerMultiProcessor; // Numero massimo di thread per SM
    int multiProcessorCount; // Numero di SM
    int regsPerBlock; // Numero di registri per blocco
    size_t sharedMemPerBlock; // Shared memory disponibile per blocco in byte
    size_t totalGlobalMem; // Memoria globale disponibile sul device in byte
    int warpSize; // Dimensione del warp in thread
};
\end{lstlisting}

\subsubsection{Ottenere le proprietà di una GPU}
\begin{verbatim}
cudaDeviceProp prop;
cudaGetDeviceProperties(&prop, numero_gpu);
\end{verbatim}

\subsubsection{Accesso alle singole proprietà}
\begin{verbatim}
prop.name
prop.major
// Altri campi...
\end{verbatim}

\subsection{Gestione della memoria GPU}

\subsubsection{Allocazione della memoria}
Alloca memoria sulla GPU specificata.
\begin{verbatim}
cudaMalloc((void**)&d_A, size);
\end{verbatim}

\subsubsection{Copia della memoria tra GPU e CPU}
Copia i dati tra CPU e GPU.
\begin{verbatim}
cudaMemcpy(A, B, size, direzione);
\end{verbatim}

\paragraph{Direzioni di copia disponibili}
\begin{itemize}
    \item \texttt{cudaMemcpyHostToDevice}
    \item \texttt{cudaMemcpyDeviceToHost}
    \item \texttt{cudaMemcpyDeviceToDevice}
    \item \texttt{cudaMemcpyDefault}
\end{itemize}
\textbf{NOTA:} I puntatori \texttt{A} e \texttt{B} allocati sono diversi tra GPU e CPU, ma con CUDA 6 è stata introdotta la Unified Memory che permette di avere un unico spazio di memoria.

\subsubsection{Liberare la memoria}
Libera la memoria precedentemente allocata sulla GPU.
\begin{verbatim}
cudaFree(A);
\end{verbatim}

\end{document}
