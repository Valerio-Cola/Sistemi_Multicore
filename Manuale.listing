int pthread_create(
    pthread_t *thread,                  // Puntatore alla struttura che                                     identifica il thread
    const pthread_attr_t *attr,         // NULL o attributi del thread
    void *(*start_routine) (void *),    // Puntatore alla funzione che                                      il thread eseguira'
    void *arg                           // Argomento della funzione
);
\end{co}
Esempio di utilizzo:
\begin{verbatim}
pthread_create(NULL, NULL, my_function, (void*)10);
\end{verbatim}
Questa chiamata crea un nuovo thread che esegue \texttt{my\_function} con l'argomento \texttt{10}.

\subsection{Attesa della Terminazione di un Thread}
\begin{verbatim}
int pthread_join(pthread_t thread, void **value_ptr);
\end{verbatim}
Questa funzione fa attendere il thread chiamante fino alla terminazione del thread specificato.

\subsection{Identificazione del Thread Corrente}
\begin{verbatim}
pthread_t pthread_self(void);
\end{verbatim}
Restituisce l'ID del thread chiamante.

\subsection{Confronto di ID di Thread}
\begin{verbatim}
int pthread_equal(pthread_t t1, pthread_t t2);
\end{verbatim}
Confronta gli ID di due thread e restituisce un valore diverso da zero se sono uguali.

\subsection{Semafori}

\subsubsection{Inizializzazione del Semaforo}
\begin{verbatim}
int sem_init(sem_t *sem, int pshared, unsigned int value);
\end{verbatim}
Inizializza un semaforo con un valore iniziale.

\subsubsection{Attesa su un Semaforo}
\begin{verbatim}
int sem_wait(sem_t *sem);
\end{verbatim}
Decrementa il semaforo. Se il valore è 0, il thread viene bloccato fino a quando il semaforo non viene incrementato.

\subsubsection{Segnalazione su un Semaforo}
\begin{verbatim}
int sem_post(sem_t *sem);
\end{verbatim}
Incrementa il semaforo e, se ci sono thread in attesa, ne sblocca uno.

\subsubsection{Ottenere il Valore del Semaforo}
\begin{verbatim}
int sem_getvalue(sem_t *sem, int *sval);
\end{verbatim}
Recupera il valore corrente del semaforo.

\subsubsection{Distruzione del Semaforo}
\begin{verbatim}
int sem_destroy(sem_t *sem);
\end{verbatim}
Rimuove il semaforo e libera le risorse.

\subsection{RWLock (Read-Write Lock)}

\subsubsection{Inizializzazione del RWLock}
\begin{lstlisting}
int pthread_rwlock_init(pthread_rwlock_t* rwlock, const pthread_rwlockattr_t* attr);
\end{lstlisting}
Inizializza un read-write lock.

\subsubsection{Bloccare in Modalità Lettura}
\begin{verbatim}
int pthread_rwlock_rdlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Blocca il rwlock per letture condivise.

\subsubsection{Bloccare in Modalità Scrittura}
\begin{verbatim}
int pthread_rwlock_wrlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Blocca il rwlock per scritture esclusive.

\subsubsection{Sbloccare il RWLock}
\begin{verbatim}
int pthread_rwlock_unlock(pthread_rwlock_t* rwlock);
\end{verbatim}
Sblocca il rwlock.

\subsubsection{Distruzione del RWLock}
\begin{verbatim}
int pthread_rwlock_destroy(pthread_rwlock_t* rwlock);
\end{verbatim}
Distrugge il rwlock e libera le risorse.

\subsection{Mutex}

\subsubsection{Inizializzazione del Mutex}
\begin{lstlisting}
int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *attr);
\end{lstlisting}
Inizializza un mutex.

\subsubsection{Bloccare il Mutex}
\begin{verbatim}
int pthread_mutex_lock(pthread_mutex_t *mutex);
\end{verbatim}
Blocca il mutex. Se il mutex è già bloccato, il thread chiamante viene messo in attesa.

\subsubsection{Sbloccare il Mutex}
\begin{verbatim}
int pthread_mutex_unlock(pthread_mutex_t *mutex);
\end{verbatim}
Sblocca il mutex.

\subsubsection{Distruzione del Mutex}
\begin{verbatim}
int pthread_mutex_destroy(pthread_mutex_t *mutex);
\end{verbatim}
Rimuove il mutex e libera le risorse.

\subsubsection{Esempio di Utilizzo del Mutex}
\begin{verbatim}
pthread_mutex_lock(&mutex);
sum += 4 * my_sum;
pthread_mutex_unlock(&mutex);
\end{verbatim}
Questo esempio dimostra come proteggere una sezione critica utilizzando un mutex.

\section{OpenMPI}

\subsection{Esecuzione della funzione \texttt{Hello()} in parallelo con \texttt{num\_thread} thread}
\begin{verbatim}
#pragma omp parallel num_threads(num_thread)
Hello();
\end{verbatim}

Oppure, puoi impostare il numero di thread in questo modo:

\begin{verbatim}
omp_set_num_threads(int num_threads);
\end{verbatim}

\subsection{Clausole di Condivisione delle Variabili}
Quando aggiungi una pragma, puoi specificare come le variabili sono condivise tra i thread:
\begin{itemize}
    \item \textbf{private(variabile)}: Ogni thread ha la propria copia della variabile, indipendente da quella esterna.
    \item \textbf{shared}: Tutte le variabili sono condivise tra i thread.
    \item \textbf{none}: Nessuna variabile è condivisa; tutte devono avere uno scope esplicito.
    \item \textbf{reduction(operatore:variabile)}: Le variabili sono private, tranne \texttt{variabile} che è utilizzata per la riduzione con l'\texttt{operatore} specificato.
    \item \textbf{firstprivate}: Le variabili sono private e inizializzate con il valore della variabile esterna.
    \item \textbf{lastprivate}: Le variabili sono private e il loro valore viene copiato nella variabile esterna dopo il blocco.
    \item \textbf{threadprivate}: Le variabili sono private e mantengono il loro valore tra diverse regioni parallel.
    \item \textbf{copyin}: Le variabili sono private e inizializzate con il valore della variabile esterna all'inizio del blocco.
    \item \textbf{copyprivate}: Simile a \texttt{copyin}, ma i valori vengono copiati anche al termine del blocco.
\end{itemize}

\subsection{Operazioni di Riduzione}
\begin{verbatim}
reduction(operatore:variabile)
\end{verbatim}

Operatori supportati: \texttt{+}, \texttt{*}, \texttt{-}, \texttt{\&}, \texttt{ |}, \texttt{\^}, \texttt{\&\&}, \texttt{||}. Ogni thread esegue l'operazione e accumula il risultato in una singola variabile.

\subsection{Controllo della Concorrenza}
\begin{itemize}
    \item \textbf{critical}: Simile a un lock, garantisce che solo un thread acceda alla sezione critica alla volta.
    \item \textbf{atomic}: Garantisce l'esecuzione atomica di operazioni specifiche, migliorando le prestazioni rispetto a \texttt{critical} quando applicabile.
\end{itemize}

\subsection{Parallelizzazione dei Cicli}
\begin{itemize}
    \item \textbf{for}: Parallelizza l'esecuzione del ciclo \texttt{for}, anche quelli annidati, a seconda della posizione della pragma.
    \item \textbf{collapse(numero\_for)}: Insieme a \texttt{for}, OpenMPI gestisce la parallelizzazione di più cicli annidati.
\end{itemize}

\subsection{Misurazione del Tempo di Esecuzione}
\begin{verbatim}
double start = omp_get_wtime();
/* codice */
double stop = omp_get_wtime();
\end{verbatim}

Calcola il tempo di esecuzione del codice tra le due chiamate a \texttt{omp\_get\_wtime()}.

\section{CUDA}

\subsection{Chiamata alla funzione \texttt{hello}}
Esecuzione della funzione \texttt{hello} in un singolo blocco con 10 thread. La chiamata è asincrona, quindi è necessario sincronizzare la GPU per attendere il completamento dell'esecuzione.
\begin{verbatim}
hello<<<1, 10>>>();
cudaDeviceSynchronize();
\end{verbatim}

\subsection{Decoratori per funzioni CUDA}
\begin{itemize}
    \item \texttt{\_\_global\_\_}: Indica che la funzione è eseguita sulla GPU e può essere chiamata dalla CPU.
    \item \texttt{\_\_device\_\_}: Indica che la funzione è eseguita sulla GPU ma può essere chiamata solo da altre funzioni eseguite sulla GPU.
    \item \texttt{\_\_host\_\_}: Indica che la funzione è eseguita sulla CPU.
\end{itemize}

\subsection{Numero di GPU disponibili}
Ottiene il numero di GPU disponibili nel sistema.
\begin{verbatim}
int deviceCount = 0;
cudaGetDeviceCount(&deviceCount);
\end{verbatim}

\subsection{Proprietà delle GPU}
Ad ogni GPU è assegnata una struttura per le relative informazioni.
\begin{lstlisting}
struct cudaDeviceProp {
    char name[256]; // Nome del device
    int major; // Major compute capability number
    int minor; // Minor compute capability number
    int maxGridSize[3]; // Dimensioni massime della griglia
    int maxThreadsDim[3]; // Dimensioni massime dei blocchi
    int maxThreadsPerBlock; // Numero massimo di thread per blocco
    int maxThreadsPerMultiProcessor; // Numero massimo di thread per SM
    int multiProcessorCount; // Numero di SM
    int regsPerBlock; // Numero di registri per blocco
    size_t sharedMemPerBlock; // Shared memory disponibile per blocco in byte
    size_t totalGlobalMem; // Memoria globale disponibile sul device in byte
    int warpSize; // Dimensione del warp in thread
};
\end{lstlisting}

\subsubsection{Ottenere le proprietà di una GPU}
\begin{verbatim}
cudaDeviceProp prop;
cudaGetDeviceProperties(&prop, numero_gpu);
\end{verbatim}

\subsubsection{Accesso alle singole proprietà}
\begin{verbatim}
prop.name
prop.major
// Altri campi...
\end{verbatim}

\subsection{Gestione della memoria GPU}

\subsubsection{Allocazione della memoria}
Alloca memoria sulla GPU specificata.
\begin{verbatim}
cudaMalloc((void**)&d_A, size);
\end{verbatim}

\subsubsection{Copia della memoria tra GPU e CPU}
Copia i dati tra CPU e GPU.
\begin{verbatim}
cudaMemcpy(A, B, size, direzione);
\end{verbatim}

\paragraph{Direzioni di copia disponibili}
\begin{itemize}
    \item \texttt{cudaMemcpyHostToDevice}
    \item \texttt{cudaMemcpyDeviceToHost}
    \item \texttt{cudaMemcpyDeviceToDevice}
    \item \texttt{cudaMemcpyDefault}
\end{itemize}
\textbf{NOTA:} I puntatori \texttt{A} e \texttt{B} allocati sono diversi tra GPU e CPU, ma con CUDA 6 è stata introdotta la Unified Memory che permette di avere un unico spazio di memoria.

\subsubsection{Liberare la memoria}
Libera la memoria precedentemente allocata sulla GPU.
\begin{verbatim}
cudaFree(A);
\end{verbatim}

\end{document}
